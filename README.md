# ğŸ“Š Kasban Churn Prediction with LLM + XGBoost

This project combines **Large Language Models (LLMs)** with a **machine learning classifier** to predict customer churn.

Instead of manually filling structured forms, the user can **write free-form text** about a customer. The LLM extracts structured features (gender, internet service, contract type, etc.) using LangChain, and these features are passed into a trained **XGBoost churn prediction model**.

---

## ğŸš€ Features

* **LLM-based feature extraction**

  * Uses `langchain-openai` with `ChatOpenAI` to parse customer descriptions.
  * Extracts fields like gender, contract type, monthly charges, etc.
  * Validated against a strict **Pydantic schema** to ensure correctness.

* **Churn classification model**

  * Trained with **XGBoost** on the Telco Customer Churn dataset.
  * Preprocessing pipeline includes scaling numeric values and encoding categorical variables.

* **FastAPI service**

  * REST API endpoint (`POST /`) to send free-text input.
  * Returns both structured features and churn prediction (`Yes` / `No`).

---

## ğŸ“‚ Project Structure

```
Kasban_Churn_LLM/
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Example environment variables
â”œâ”€â”€ README.md                   # Project documentation
â”‚
â”œâ”€â”€ data/                       # Raw dataset
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”‚
â”œâ”€â”€ src/
    â”œâ”€â”€ llm/                    # LLM extraction logic
    â”‚   â”œâ”€â”€ schema.py           # Pydantic schema for customer features
    â”‚   â”œâ”€â”€ extractor.py        # LangChain LLM + parser
    â”‚   â””â”€â”€ test.py             # Test LLM extraction
    â”‚
    â”œâ”€â”€ models/                 # ML model training and inference
    â”‚   â”œâ”€â”€ train_xgb.py        # XGBoost training script
    â”‚   â”œâ”€â”€ predict.py          # Load trained model and predict
    â”‚   â”œâ”€â”€ test.py             # Evaluate model performance
    â”‚   â””â”€â”€ model_XGBoost.pkl   # Saved trained model
    â”‚
    â”œâ”€â”€ utils/                  # Data preprocessing pipeline
    â”‚   â””â”€â”€ data_preprocessing_pipeline.py
    â”‚
    â”œâ”€â”€ serve/                  # Serving layer
    â”‚   â”œâ”€â”€ main.py             # FastAPI application
    â”‚   â””â”€â”€ test_llm_with_xgb.py# Test full pipeline (LLM â†’ XGB)
    â”‚
    â””â”€â”€ notebooks/              # Experiments
       â””â”€â”€ EDA.ipynb
```

---

## âš™ï¸ Setup

### 1. Clone the repository

```bash
git clone https://github.com/MoustafaMohammedd/Kasban_Churn_Prediction_with_LLM-XGBoost.git
cd Kasban_Churn_Prediction_with_LLM-XGBoost
```

### 2. Create virtual environment & install dependencies

```bash
python -m venv venv
source venv/bin/activate    # On Linux/Mac
venv\Scripts\activate       # On Windows

pip install -r requirements.txt
```

### 3. Configure environment variables

Copy `.env.example` â†’ `.env` and fill in:

```env
API_KEY="your_api_key"
BASE_URL="https://api.openai.com/v1"
MODEL_NAME="openai/gpt-oss-20b:free"
```

### 4. Train the churn model

```bash
python src/models/train_xgb.py
```

This will save the model as `src/models/model_XGBoost.pkl`.

---

## â–¶ï¸ Running the API

### Start FastAPI server

```bash
uvicorn src.serve.main:app --reload
```

### Test endpoint

POST request to `http://127.0.0.1:8000/docs

**Example input:**

```json
{
  "text": "A 45-year-old female with fiber optic internet, streaming TV, no partner, two dependents, contract month-to-month, paperless billing, tenure 12 months, monthly charges 70.5, total charges 846.0."
}
```

**Example output:**

```json
{
  "churn_prediction": "Yes",
  "features": {
    "gender": "Female",
    "SeniorCitizen": "No",
    "Partner": "No",
    "Dependents": "Yes",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "Yes",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 70.5,
    "TotalCharges": 846.0
  }
}
```

---

## ğŸ§ª Testing

* Test LLM feature extraction only:

  ```bash
  python src/llm/test.py
  ```

* Test ML model predictions only:

  ```bash
  python src/models/test.py
  ```

* Test full pipeline (LLM â†’ XGB â†’ prediction):

  ```bash
  python src/serve/test_llm_with_xgb.py
  ```

```

---

## ğŸ“ˆ Next Steps

* Improve LLM prompt to handle missing or ambiguous customer details.
* Add more ML algorithms for comparison (LightGBM, CatBoost).
* Add a simple UI for non-technical users.

---

ğŸ”¥ Now you have a full end-to-end pipeline:
**Free-text â†’ LLM Feature Extraction â†’ XGBoost Prediction â†’ FastAPI Service**.


